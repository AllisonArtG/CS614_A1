{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+MeCmjg27/FtvUpEbqyqf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["**Setup and Dataset Preprocessing**"],"metadata":{"id":"2FpU7fMEdFho"}},{"cell_type":"markdown","source":["Imports"],"metadata":{"id":"9hWpVCAlBxll"}},{"cell_type":"code","source":["from google.colab import drive, files\n","import copy, os, shutil, time\n","from zipfile import ZipFile\n","import torch\n","from torch import nn, cuda, device, optim\n","from torch.utils.data import Dataset, random_split, DataLoader\n","from torchvision import datasets, models, transforms\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2, glob"],"metadata":{"id":"28Eh6VzZdBIJ","executionInfo":{"status":"ok","timestamp":1682739468468,"user_tz":240,"elapsed":162,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["Dataset directory name and it's intended path"],"metadata":{"id":"FKhJwUW2l0zv"}},{"cell_type":"code","source":["dir_name = \"indian_birds_dataset\"\n","dataset_path = os.path.join(\"/content\", dir_name)"],"metadata":{"id":"bGP4yvX3qhIc","executionInfo":{"status":"ok","timestamp":1682739468881,"user_tz":240,"elapsed":209,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":["Mount Google Drive locally, to access dataset - `archive.zip`."],"metadata":{"id":"DkDHergJLOJb"}},{"cell_type":"code","source":["drive.mount(\"/content/drive\")"],"metadata":{"id":"GIiImZH8LZxy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Extracts the dataset into `\"/content\"`. **NOTE**: Replace the value `dataset_path` with the path to `archive.zip` in Google Drive (e.g. `\"/content/drive/MyDrive/.../archive.zip\"`)."],"metadata":{"id":"kv4Ou5MCRPUd"}},{"cell_type":"code","source":["dataset_zip_path = \"/content/drive/MyDrive/CS614/archive.zip\"\n","\n","with ZipFile(dataset_zip_path, \"r\") as zip:\n","  zip.extractall(\"/content\")"],"metadata":{"id":"xHkfp8vKNCDi","executionInfo":{"status":"ok","timestamp":1682739522548,"user_tz":240,"elapsed":24548,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":["Moves the dataset's root directory from `\"training_dataset\"` to `\"indian_birds_dataset\"`"],"metadata":{"id":"cxFCdiO1Ddsf"}},{"cell_type":"code","source":["shutil.move(\"/content/training_set\", dataset_path)"],"metadata":{"id":"tVJuZoSdyh2p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Delete accidental directory\n"],"metadata":{"id":"s8iE9rZAR7cp"}},{"cell_type":"code","source":["def delete_dir(path):\n","  if os.path.isdir(path):\n","    print(f\"Deleting {path}\")\n","    shutil.rmtree(path, ignore_errors=True)"],"metadata":{"id":"Dm_W2VSMRYn8","executionInfo":{"status":"ok","timestamp":1682739522554,"user_tz":240,"elapsed":1,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["delete_dir(os.path.join(dataset_path, \"training_set\"))"],"metadata":{"id":"7fYgVEiVSAZO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Static dataset and model variables"],"metadata":{"id":"QArdi05TtSpW"}},{"cell_type":"code","source":["input_size = 299\n","num_classes = 25\n","batch_size_train = 20\n","batch_size_vt = 20\n","num_epochs = 1 \n","num_workers = 2\n","learning_rate = 0.0001\n","momentum = 0.9\n","\n","dataset_split = {\"train\" : 0.8, \"valid\" : 0.1, \"test\": 0.1}"],"metadata":{"id":"UlpxwixMtNJL","executionInfo":{"status":"ok","timestamp":1682739523170,"user_tz":240,"elapsed":3,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["Model"],"metadata":{"id":"4XhB09J2wNdY"}},{"cell_type":"code","source":["model = models.resnet34(weights=\"DEFAULT\")\n","num_features = model.fc.in_features\n","model.fc = nn.Linear(num_features, num_classes)"],"metadata":{"id":"eJffIkf4wMLL","executionInfo":{"status":"ok","timestamp":1682739524047,"user_tz":240,"elapsed":879,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["Prepare the Dataset"],"metadata":{"id":"irC8vtseV45H"}},{"cell_type":"markdown","source":["Because `random_split` doesn't actually split the dataset, but just keeps the indices of the subsets. This class allows me to apply different transformations to the training dataset vs. the testing and validation datasets."],"metadata":{"id":"OtZCGFvn6occ"}},{"cell_type":"code","source":["class WrapperDataset(Dataset):\n","    def __init__(self, subset, transform=None):\n","        self.subset = subset\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        x, y = self.subset[index]\n","        if self.transform:\n","            x = self.transform(x)\n","        return x, y\n","        \n","    def __len__(self):\n","        return len(self.subset)"],"metadata":{"id":"4fbPimDjowA0","executionInfo":{"status":"ok","timestamp":1682739524054,"user_tz":240,"elapsed":6,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":["Dataset Preprocessing"],"metadata":{"id":"3tjl-hx6H_k8"}},{"cell_type":"code","source":["full_dataset = datasets.ImageFolder(dataset_path)\n","\n","class_to_idx = full_dataset.class_to_idx\n","\n","generator = torch.Generator().manual_seed(42)\n","_train, _valid, _test = random_split(full_dataset, [x for x in dataset_split.values()], generator=generator)\n","\n","num_total_samples = len(_train.dataset)\n","num_samples = {}\n","for i in range(len(dataset_split)):\n","  ds = list(dataset_split.keys())[i]\n","  num_samples[ds] = int(dataset_split[ds] * num_total_samples)\n","\n","train_transform = transforms.Compose([\n","    transforms.Resize(input_size),\n","    transforms.CenterCrop(input_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","valid_test_transform = transforms.Compose([\n","    transforms.Resize(input_size),\n","    transforms.CenterCrop(input_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","train = WrapperDataset(_train, transform=train_transform)\n","test = WrapperDataset(_test, transform=valid_test_transform)\n","valid = WrapperDataset(_valid, transform=valid_test_transform)\n","\n","train_loader = DataLoader(train , batch_size=batch_size_train, num_workers=num_workers,  shuffle=True)\n","valid_loader = DataLoader(valid, batch_size=batch_size_vt, num_workers=num_workers)\n","test_loader = DataLoader(test, batch_size=batch_size_vt, num_workers=num_workers)"],"metadata":{"id":"6CVZNIE7W-mF","executionInfo":{"status":"ok","timestamp":1682739524054,"user_tz":240,"elapsed":6,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":["List of classes and mapping from index to class"],"metadata":{"id":"oXTQ-sUbp1Pt"}},{"cell_type":"code","source":["classes = list(class_to_idx.keys())\n","\n","idx_to_class = {}\n","for clas, index in class_to_idx.items():\n","  idx_to_class[index] = clas\n","print(idx_to_class)"],"metadata":{"id":"stbEtLWYV4Gk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GPU/CPU"],"metadata":{"id":"NG0CGt2EZ8en"}},{"cell_type":"code","source":["devic = device(\"cuda:0\" if cuda.is_available() else \"cpu\")\n","print(\"device:\", devic)"],"metadata":{"id":"Pd34wqAwZ67G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = model.to(devic)"],"metadata":{"id":"4tlV3_CIxJTt","executionInfo":{"status":"ok","timestamp":1682739524232,"user_tz":240,"elapsed":1,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"xTGzFO3POUyA"}},{"cell_type":"markdown","source":["**Testing**"],"metadata":{"id":"lk08bgXZJF0h"}},{"cell_type":"markdown","source":["Load trained model's weights\n","\n","**NOTE:** Replace the value of `model_drive_path` with the path to the model weights file, `model`, in Google Drive (e.g. `\"/content/drive/MyDrive/.../model\"`)."],"metadata":{"id":"2dS_ra34ntQ8"}},{"cell_type":"code","source":["model_drive_path = \"drive/MyDrive/my_resnet_model\"\n","\n","model_dict = torch.load(model_drive_path, map_location=torch.device(devic))\n","#print(model_dict.keys())\n","\n","model.load_state_dict(model_dict)"],"metadata":{"id":"J3HEb2m_nsE2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`print_eval_update()` is used to print the number of samples seen and accuracy in `evaluate()`."],"metadata":{"id":"2XglWGnYqRAk"}},{"cell_type":"code","source":["def print_eval_update(num_correct, current_samples, total_num_samples):\n","  print(\"num_correct:\", num_correct)\n","  print(\"current_num_samples:\", current_samples)\n","  print(\"current_accuracy: {:.4f}\".format(num_correct/current_samples))\n","  print(\"total_accuracy: {:.4f}\".format(num_correct/total_num_samples))\n","  print()"],"metadata":{"id":"ZunQK6kIy_I6","executionInfo":{"status":"ok","timestamp":1682739524662,"user_tz":240,"elapsed":6,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":["`evaluate()` evaluates the model's performance on the validation and testing datasets, it also saves a confusion matrix of the results\n","\n","Comment out the call to `print_eval_update()` if you want to reduce the output"],"metadata":{"id":"LC3U2-9cOpMz"}},{"cell_type":"code","source":["def evaluate(model, device, data_loader, subset_name, num_samples_subset, classes):\n","\n","  model.eval()\n","\n","  num_classes = len(classes)\n","  correct = 0\n","  samples = 0\n","  all_preds = []\n","  all_actual = []\n","\n","  for inputs, labels in data_loader:\n","    outputs = model(inputs)\n","    _, preds = torch.max(outputs, 1)\n","    correct += torch.sum(preds == labels.data)\n","    \n","    _preds = preds.data.cpu().numpy()\n","    _labels = labels.data.cpu().numpy()\n","    all_preds.extend(_preds)\n","    all_actual.extend(_labels)\n","\n","    samples += len(preds)\n","\n","    if samples % 100 == 0:\n","      print_eval_update(correct.item(), samples, num_samples_subset)\n","  \n","  accuracy = correct.item()/num_samples_subset\n","  print(\"\\naccuracy\", accuracy)\n","\n","  conf_matrix = confusion_matrix(all_actual, all_preds)\n","  cmp = ConfusionMatrixDisplay(conf_matrix)\n","  fig, ax = plt.subplots(figsize=(10,10))\n","  cmp.plot(ax=ax)\n","  plt.savefig(f'/content/{subset_name}_confusion_matrix.png')\n","  \n"],"metadata":{"id":"LKTEbOZBnxnm","executionInfo":{"status":"ok","timestamp":1682739524663,"user_tz":240,"elapsed":7,"user":{"displayName":"Allison Gong","userId":"03630911304537870557"}}},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":["Validation Dataset Evaluation"],"metadata":{"id":"UjqEoRA5Qwm2"}},{"cell_type":"code","source":["print(\"valid total samples:\", num_samples[\"valid\"], \"\\n\")\n","evaluate(model, device, valid_loader, \"valid\", num_samples[\"valid\"], classes)"],"metadata":{"id":"cHvU99cZQv1f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test Dataset Evaluation"],"metadata":{"id":"a_KRuyDgQ3sK"}},{"cell_type":"code","source":["print(\"test total samples:\", num_samples[\"test\"], \"\\n\")\n","evaluate(model, device, test_loader, \"test\", num_samples[\"test\"], classes)"],"metadata":{"id":"-QfbuxQbQ3Dp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test Examples"],"metadata":{"id":"nbPIHyRYRig1"}},{"cell_type":"markdown","source":["`generate_sample_subset()` creates a subset of the `indian_birds_dataset`, specifically a directory in the same structure as `indian_birds_dataset`, given a list of images"],"metadata":{"id":"cF3CeaJxSomO"}},{"cell_type":"code","source":["def generate_sample_subset(filepaths, subset_dataset_path):\n","  import glob\n","  \n","  if os.path.isdir(subset_dataset_path) == False:\n","    os.makedirs(subset_dataset_path)\n","\n","  dirs = glob.glob(dataset_path + \"/*\")\n","  new_images = []\n","  for dir in dirs:\n","    dir_basename = os.path.basename(dir)\n","    dir_path = os.path.join(subset_dataset_path, os.path.basename(dir))\n","    if os.path.isdir(dir_path) == False:\n","      os.makedirs(dir_path)\n","  \n","  for file in filepaths:\n","    og_filepath = os.path.join(dataset_path, file)\n","    new_filepath = os.path.join(subset_dataset_path, file)\n","    if os.path.isfile(og_filepath) == True and os.path.isfile(new_filepath) == False:\n","      shutil.copyfile(og_filepath, new_filepath)\n","      if os.path.isfile(new_filepath) == False:\n","        print(f\"Failed to copy over {og_filepath}.\")\n","      else:\n","        print(new_filepath)\n","      new_images.append(new_filepath)\n","  print(\"Done creating subset of dataset.\")\n","  return new_images\n","\n","\n","\n","\n"],"metadata":{"id":"oqzVk7o0b3ML"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creates the sample dataset `indian_birds_dataset_subset`"],"metadata":{"id":"aSVV2OhovvGn"}},{"cell_type":"code","source":["subset_dataset_path = \"/content/indian_birds_dataset_subset\"\n","\n","#Some test examples pulled from the Test Dataset\n","incorrect = [\"Indian Peacock/ML347405821.jpg\", \n","             \"House Crow/ML503964861.jpg\", \n","             \"Indian Grey Hornbill/ML77061781.jpg\", \n","             \"Brown-Headed Barbet/ML290838891.jpg\", \n","             \"Gray Wagtail/ML313524561.jpg\", \n","             \"Red-Wattled Lapwing/ML98206961.jpg\", \n","             \"Ruddy Shelduck/ML396122561.jpg\", \n","             \"House Crow/ML110722671.jpg\", \n","             \"Indian Roller/ML183145991.jpg\"]\n","\n","correct = [ \"Indian Grey Hornbill/ML106408871.jpg\", \n","           \"Indian Peacock/ML359756441.jpg\", \n","           \"Common Myna/ML268701161.jpg\", \n","           \"Common Rosefinch/ML72047811.jpg\", \n","           \"White-Breasted Waterhen/ML227087131.jpg\", \n","           \"White Wagtail/ML350263231.jpg\", \n","           \"House Crow/ML166883151.jpg\", \n","           \"Northern Lapwing/ML414357021.jpg\", \n","           \"Indian Pitta/ML528943911.jpg\", \n","           \"Asian Green Bee-Eater/ML196703651.jpg\",\n","           \"Common Kingfisher/ML204444751.jpg\",\n","           \"Rufous Treepie/ML85279711.jpg\",\n","           \"Sarus Crane/ML136277331.jpg\",\n","           \"White Wagtail/ML152781481.jpg\",\n","           \"Coppersmith Barbet/ML79408821.jpg\",\n","           \"Hoopoe/ML205105201.jpg\",\n","           \"Cattle Egret/ML388884741.jpg\",\n","           \"White-Breasted Kingfisher/ML205857601.jpg\",\n","           \"Forest Wagtail/ML397067501.jpg\",\n","           \"Common Tailorbird/ML166735161.jpg\",\n","           \"Jungle Babbler/ML32855221.jpg\"]\n","\n","delete_dir(os.path.join(subset_dataset_path, \"indian_birds_dataset\"))\n","\n","subset_image_paths = generate_sample_subset(incorrect + correct, subset_dataset_path)"],"metadata":{"id":"TLsxCKh7RkZN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Prepares the sample dataset"],"metadata":{"id":"mHwl-5Ohv0Us"}},{"cell_type":"code","source":["subset_transform = transforms.Compose([\n","    transforms.Resize(input_size),\n","    transforms.CenterCrop(input_size),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","subset_dataset = datasets.ImageFolder(subset_dataset_path, transform=subset_transform)\n","\n","subset_loader = DataLoader(subset_dataset, batch_size=1, num_workers=num_workers)"],"metadata":{"id":"XJFomV64_37F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`evaluate_subset()` evaluates the sample dataset using the model and prints out in input image with predicted and actual class"],"metadata":{"id":"LflCSj-swGwo"}},{"cell_type":"code","source":["def evaluate_subset(model, device, data_loader, idx_to_class):\n","\n","  model.eval()\n","\n","  i = 0\n","  for inputs, label in data_loader:\n","    outputs = model(inputs)\n","    _, pred = torch.max(outputs, 1)\n","    label = label[0].item()\n","    pred = pred[0].item()\n","\n","    img_path = data_loader.dataset.samples[i][0]\n","    img = cv2.imread(img_path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n","\n","    plt.imshow(img)\n","    plt.show()\n","    print(img_path)\n","    print(\"actual:\", label, idx_to_class[label])\n","    print(\"predicted:\", pred, idx_to_class[pred])\n","    print(\"---\")\n","\n","    i += 1"],"metadata":{"id":"_jugAhpEQlBD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Show Test Examples (Scroll through the output, there are a lot of example images)"],"metadata":{"id":"VCPYNUscCDBN"}},{"cell_type":"code","source":["evaluate_subset(model, device, subset_loader, idx_to_class)"],"metadata":{"id":"tJ7j8e7vCCCN"},"execution_count":null,"outputs":[]}]}